{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":10125851,"sourceType":"datasetVersion","datasetId":6248577}],"dockerImageVersionId":31040,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Import Library","metadata":{}},{"cell_type":"code","source":"import os\nimport cv2\nimport csv\nfrom tqdm.auto import tqdm\nimport pandas as pd","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-26T07:32:47.549887Z","iopub.execute_input":"2025-05-26T07:32:47.550212Z","iopub.status.idle":"2025-05-26T07:32:47.555269Z","shell.execute_reply.started":"2025-05-26T07:32:47.550191Z","shell.execute_reply":"2025-05-26T07:32:47.554226Z"}},"outputs":[],"execution_count":17},{"cell_type":"markdown","source":"# Setup Dataset","metadata":{}},{"cell_type":"code","source":"# Paths\ndata_path = \"/kaggle/input/ff-c23/FaceForensics++_C23\"\noutput_dir = \"frames_cropped_new\"\nos.makedirs(output_dir, exist_ok=True)\n\n# Debug settings\nDEBUG_MODE = True\nDEBUG_VIDEOS_PER_CATEGORY = 2  # number of videos per category to debug\n\n# NEW: maksimum crops per video\nMAX_CROPS_PER_VIDEO = 1\n\n# Category-to-label mapping\ncategories = {\n    \"original\": 0,\n    \"DeepFakeDetection\": 1,\n    \"Deepfakes\": 1,\n    \"Face2Face\": 1,\n    \"FaceSwap\": 1,\n    \"FaceShifter\":1,\n    \"NeuralTextures\": 1\n}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-26T08:09:47.671330Z","iopub.execute_input":"2025-05-26T08:09:47.672121Z","iopub.status.idle":"2025-05-26T08:09:47.677735Z","shell.execute_reply.started":"2025-05-26T08:09:47.672095Z","shell.execute_reply":"2025-05-26T08:09:47.676508Z"}},"outputs":[],"execution_count":38},{"cell_type":"markdown","source":"# Cropping Face","metadata":{}},{"cell_type":"code","source":"# Initialize face detector\nface_cascade = cv2.CascadeClassifier(\n    cv2.data.haarcascades + 'haarcascade_frontalface_default.xml'\n)\n\n# Prepare CSV rows\ncsv_rows = [[\"filepath\", \"label\"]]\n\n# Loop through each category and video\nfor category, label in tqdm(categories.items(),desc=\"categories\"):\n    print(f\"\\nCategory: {category}\")\n    processed_count = 0\n    cat_path = os.path.join(data_path, category)\n\n    for root, _, files in os.walk(cat_path):\n        for file in files:\n            if not file.endswith('.mp4'):\n                continue\n            if DEBUG_MODE and processed_count >= DEBUG_VIDEOS_PER_CATEGORY:\n                break\n\n            video_path = os.path.join(root, file)\n            print(f\"Processing video: {video_path}\")\n\n            cap = cv2.VideoCapture(video_path)\n            fps = cap.get(cv2.CAP_PROP_FPS) or 30\n            interval = int(fps)  # 1 frame per second\n            frame_idx = 0\n            saved_idx = 0\n\n            while True:\n                ret, frame = cap.read()\n                if not ret or saved_idx >= MAX_CROPS_PER_VIDEO:\n                    # berhenti jika video habis atau sudah mencapai batas crop\n                    break\n\n                # Only process one frame per second\n                if frame_idx % interval == 0:\n                    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n                    faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n                    if len(faces) > 0:\n                        x, y, w, h = faces[0]  # ambil wajah pertama\n                        face_crop = frame[y:y+h, x:x+w]\n                        save_fname = f\"{category}_{os.path.splitext(file)[0]}_{saved_idx:04d}.jpg\"\n                        save_path = os.path.join(output_dir, save_fname)\n                        cv2.imwrite(save_path, face_crop)\n                        csv_rows.append([save_path, label])\n                        saved_idx += 1\n\n                frame_idx += 1\n\n            cap.release()\n            processed_count += 1\n\n        if DEBUG_MODE and processed_count >= DEBUG_VIDEOS_PER_CATEGORY:\n            break\n\n# Write out the labels CSV\nwith open(\"labels.csv\", \"w\", newline=\"\") as f:\n    writer = csv.writer(f)\n    writer.writerows(csv_rows)\n\nprint(\"\\nDone! Cropped frames saved in\", output_dir)\nprint(\"Labels list saved to labels.csv\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-05-26T08:09:50.402214Z","iopub.execute_input":"2025-05-26T08:09:50.402608Z","iopub.status.idle":"2025-05-26T08:10:03.723011Z","shell.execute_reply.started":"2025-05-26T08:09:50.402583Z","shell.execute_reply":"2025-05-26T08:10:03.721674Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"categories:   0%|          | 0/7 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c66486f5d14d4039a62e34e887bcdd6a"}},"metadata":{}},{"name":"stdout","text":"\nCategory: original\nProcessing video: /kaggle/input/ff-c23/FaceForensics++_C23/original/123.mp4\nProcessing video: /kaggle/input/ff-c23/FaceForensics++_C23/original/738.mp4\n\nCategory: DeepFakeDetection\nProcessing video: /kaggle/input/ff-c23/FaceForensics++_C23/DeepFakeDetection/02_09__kitchen_pan__9TDCEK1Q.mp4\nProcessing video: /kaggle/input/ff-c23/FaceForensics++_C23/DeepFakeDetection/02_13__exit_phone_room__CP5HFV3K.mp4\n\nCategory: Deepfakes\nProcessing video: /kaggle/input/ff-c23/FaceForensics++_C23/Deepfakes/479_706.mp4\nProcessing video: /kaggle/input/ff-c23/FaceForensics++_C23/Deepfakes/481_469.mp4\n\nCategory: Face2Face\nProcessing video: /kaggle/input/ff-c23/FaceForensics++_C23/Face2Face/479_706.mp4\nProcessing video: /kaggle/input/ff-c23/FaceForensics++_C23/Face2Face/481_469.mp4\n\nCategory: FaceSwap\nProcessing video: /kaggle/input/ff-c23/FaceForensics++_C23/FaceSwap/479_706.mp4\nProcessing video: /kaggle/input/ff-c23/FaceForensics++_C23/FaceSwap/481_469.mp4\n\nCategory: FaceShifter\nProcessing video: /kaggle/input/ff-c23/FaceForensics++_C23/FaceShifter/479_706.mp4\nProcessing video: /kaggle/input/ff-c23/FaceForensics++_C23/FaceShifter/481_469.mp4\n\nCategory: NeuralTextures\nProcessing video: /kaggle/input/ff-c23/FaceForensics++_C23/NeuralTextures/479_706.mp4\nProcessing video: /kaggle/input/ff-c23/FaceForensics++_C23/NeuralTextures/481_469.mp4\n\nDone! Cropped frames saved in frames_cropped_new\nLabels list saved to labels.csv\n","output_type":"stream"}],"execution_count":39},{"cell_type":"code","source":"df = pd.read_csv('labels.csv')\nprint(f\"Label unique : {df['label'].unique()}\\n\")\nprint(f\"Label Count: {df['label'].value_counts()}\\n\")\ndf.info()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-26T08:09:34.285659Z","iopub.execute_input":"2025-05-26T08:09:34.285970Z","iopub.status.idle":"2025-05-26T08:09:34.308401Z","shell.execute_reply.started":"2025-05-26T08:09:34.285949Z","shell.execute_reply":"2025-05-26T08:09:34.307347Z"}},"outputs":[{"name":"stdout","text":"Label unique : [0 1]\n\nLabel Count: label\n1    5974\n0    1000\nName: count, dtype: int64\n\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 6974 entries, 0 to 6973\nData columns (total 2 columns):\n #   Column    Non-Null Count  Dtype \n---  ------    --------------  ----- \n 0   filepath  6974 non-null   object\n 1   label     6974 non-null   int64 \ndtypes: int64(1), object(1)\nmemory usage: 109.1+ KB\n","output_type":"stream"}],"execution_count":37}]}